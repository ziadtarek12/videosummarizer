{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Demo Notebook - Modular Video Summarization\n\nThis demo shows how to run the modular scripts on a single video."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "source": ["# Install required packages (run once)\n!pip install opencv-python-headless librosa torch torchvision pytorch-grad-cam ultralytics facenet-pytorch scenedetect scikit-learn tqdm seaborn datasets --quiet"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "source": ["from pathlib import Path\nimport sys\nsys.path.append('/mnt/data/video_sum_project')\nfrom preprocess import sample_frames, extract_audio_rms\nfrom embed import MobileNetEmbed, batch_embed, simclr_refine\nfrom select import method_A_kmeans, method_B_visual_audio, method_C_mmr, frames_to_keyshots\nfrom explain import yolo_objects_on_frames, textual_rationale_for_shot\nfrom eval import fscore_vs_gt\n\nVIDEO = '/kaggle/input/demo-video/demo.mp4'  # change to your uploaded path\nOUTDIR = '/mnt/data/video_sum_project/outputs'\nPath(OUTDIR).mkdir(parents=True, exist_ok=True)\n\n# Sample\nframes, ts, idxs, fps, duration = sample_frames(VIDEO, stride_sec=1.0, resize=224)\nprint('Frames', len(frames), 'duration', duration)\n\n# Embeds\nmodel = MobileNetEmbed(device='cuda' if torch.cuda.is_available() else 'cpu').to('cuda' if torch.cuda.is_available() else 'cpu').eval()\nembs = batch_embed(model, frames, batch=64, device='cuda' if torch.cuda.is_available() else 'cpu')\n\n# (optional) SimCLR-lite refine\nembs_refined = simclr_refine(embs, epochs=2, batch=64, device='cuda' if torch.cuda.is_available() else 'cpu')\n\n# Audio\naudio_scores = extract_audio_rms(VIDEO, ts)\n\n# Methods\nselA, _ = method_A_kmeans(embs_refined, k=12)\nselB, _ = method_B_visual_audio(embs_refined, audio_scores, k=12)\nselC = method_C_mmr(embs_refined, scores=(audio_scores+embs_refined.mean(axis=1)), k=12, lengths=[2.0]*len(embs_refined), budget_sec=20.0)\n\n# Keyshots\nshotsA = frames_to_keyshots(selA, ts, stride_sec=1.0, budget_sec=20.0)\nshotsB = frames_to_keyshots(selB, ts, stride_sec=1.0, budget_sec=20.0)\nshotsC = frames_to_keyshots(selC, ts, stride_sec=1.0, budget_sec=20.0)\n\nprint('Shots A', shotsA)\nprint('Shots B', shotsB)\nprint('Shots C', shotsC)\n\n# Explain\nlabelsA = yolo_objects_on_frames([frames[i] for i in selA])\nfor i,lab in zip(selA, labelsA):\n    print(f'Frame {i} rationale:', textual_rationale_for_shot(lab, audio_peak=False))\n\n# Save a few keyframes\nimport cv2\nfor j,i in enumerate(selA[:6]):\n    p = f'{OUTDIR}/A_key_{j}.jpg'\n    cv2.imwrite(p, cv2.cvtColor(frames[i], cv2.COLOR_RGB2BGR))\nprint('Saved keyframes to', OUTDIR)\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}